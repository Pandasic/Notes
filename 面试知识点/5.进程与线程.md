---
title: 5.进程与线程
tag: [计算机课程学习,面试知识点,]
---
# 进程与线程



## 进程、线程比较

* 进程:

  *  运行时程序的封装 是系统进行资源分配和调度的基本单位 实现了操作系统的并发

* 线程:
  * 进程的子任务,CPU 的调度和排分的基本单位。用于保证程序的实时性 实现进程内部的并发
  * 线程是操作系统可识别的最小执行和调度单位
  * 每个线程都独自占用一个虚拟处理器:独自的寄存器组,指令计数器和处理器状态。
  * 每个线程完成不同的任务,但是共享同一地址空间 (也就是同样的动态内存,映射文件,目标代码等等),打开的文件队列和其他内核资源
  
* 区别

* | 进程                                             | 线程                                                         |
  | ------------------------------------------------ | ------------------------------------------------------------ |
  | 而一个进程可以有多个线程,但至少有一个线程        | 一个线程只能属于一个进程线程依赖于进程而存在。               |
  | 执行过程中拥有独立的内存单元                     | 多个线程共享进程的内存                                       |
  | 资源分配的最小单位                               | CPU调度的最小单位                                            |
  | 切换/撤销的时候 系统开销大【分配、回收资源IO等】 | 相比于进程开销小                                             |
  | 进程键通信IPC                                    | 线程可以通过全局变量来通信 需要 同步和互斥手段加以辅助 拥有相同的内存地址 无需系统内核干预 |
  | 不会互相影响                                     | 一个线程挂掉可能会导致整个进程挂掉                           |
  | 多核 多机分布                                    | 多核分布                                                     |
  
* > 内存 :(资源分配给进程,同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段(代码和常量), 数据段(全局变量和静态变量),扩展段(堆存储)。但是每个线程拥有自己的栈段,栈段又叫 运行时段,用来存放所有局部变量和临时变量。)
  
* 进程优劣

  * 进程可以使多个程序能并发执行,以提高资源的利用率和系统的吞吐量;
  * 程在同一时间只能干一件事 
  * 进程在执行的过程中如果阻塞,整个进程就会挂起,即使进程中有些工作不依赖于等待的资源,仍然不会执行。

* 线程优劣

  * 粒度更小 较少并发执行所需要符出的时空开销
  * 切换效率高 代价小
  * 通信机制快捷
  * CPU 有效 不大于CPU数目时候不同线程运行在不同CPU 上
  * 改善数据结构

* 使用场景

  * 多进程模型的优势是 CPU 多线程模型主要优势为线程间切换代价较小,因此适用于 I/O 密集型的工作场景,因此 I/O
  * 密集型的工作场景经常会由于 I/O 阻塞导致频繁的切换线程。同时,多线程模型也适用于单机多 核分布式场景。
  * 多进程模型,适用于 CPU 密集型。同时,多进程模型也适用于多机分布式场景中,易于多机 扩展。

##  进程间通信方式

* 管道

  * 包括无名管道和命名管道:用于亲缘关系的符字进程间的通信,有名管道除了具有管道所具有的通过能外,允许无亲缘关系的进程间的通信
  * 普通管道PIPE:
    * 半双工【数据只能在一个方向上流动】具有固定的读端和写端
    * 只能用于具有亲缘关系的进程之间的通信(也是父子进程或者兄弟进程之间)
    * 它可以看成是一种特殊的文件,对于它的读写也可以使用普通的 read、write 等函数。但是它不是普通的文件,并不属于其他任何文件系统,并且只存在于内存中。
  * 命名管道 FIFO:
    * FIFO 可以在无关的进程之间交换数据 
    * FIFO 有路径名与之相关联,它以一种特殊设备文件形式存在于文件系统中。

* 系统IPC

  * 消息队列
    * 消息队列,是消息的链接表,存放在内核中。一个消息队列由一个标识符(即队列 ID)来标记。 
    * 消息队列克服了信号传递信息少,管道只能承载无格式字节流以及缓冲区大小受限等特 点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息;对消息队列有读权限得进程则可以从消息队列中读取信息;
    * 特点
      * 消息队列是面向记录的,其中的消息具有特定的格式以及特定的优先级
      * 消息队列独立于发送与接收进程。进程终止时,消息队列及其内容并不会被删除
      * 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取
    
  * 信号量
    * 信号量用于进程间同步,若要在进程间传递数据需要结合共享内存。
    * 信号量基于操作系统的 PV 操作,程序对信号量的操作都是原子操作
    * 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1,而且可以加减任意正整数
    * 支持信号量组。
    * 信号 是一个比较复杂的通信方式,用于同志接受进程某个时间已经发生。
  
* 共享内存
  
    * 它使得多个进程可以访问同一块内存空间,不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作,如互斥锁和信号量等 
    * 特点
      * 共享内存是最快的一种 IPC,因为进程是直接对内存进行存取 
      * 因为多个进程可以同时操作,所以需要进行同步 
    * 信号量+共享内存通常结合在一起使用,信号量用来同步对共享内存的访问
  
* 套接字 SOCKET:
  
    socket 也是一种进程间通信机制,与其他通信机制不同的是,它可用于不同主机之间的进程通信

## 线程间的通信方式

* 临界区:通过多线程的串行化来访问公共资源或一段代码,速度快,适合控制数据访问; 
* 互斥量 Synchronized/Lock:采用互斥对象机制,只有拥有互斥对象的线程才有访问公共资
  源的权限。因为互斥对象只有一个,所以可以保证公共资源不会被多个线程同时访问
* 信号量 Semphare:为控制具有有限数量的用户资源而设计的,它允许多个线程在同一时刻
  去访问同一个资源,但一般需要限制同一时刻访问此资源的最大线程数目。 
* 事件(信号),Wait/Notify:通过通知操作的方式来保持多线程同步,还可以方便的实现多
  线程优先级的比较操作

###  游戏服务器进程

游戏服务器应该为每个用户开辟一个进程。因为同一进程间的线程会相互影响,一个线程死
掉会影响其他线程,从而导致进程崩溃。因此为了保证不同用户之间不会相互影响,应该为每个 用户开辟一个进程

## 常用线程模型

###  Future 模型

该模型通常在使用的时候需要结合 **Callable** 接口配合使用。
Future 是把结果放在将来获取,当前主线程并不急于获取处理结果。允许子线程先进行处理一 段时间,处理结束之后就把结果保存下来,当主线程需要使用的时候再向子线程索取。 Callable 是类似于 Runnable 的接口,其中 call 方法类似于 run 方法,所不同的是 run 方法不能抛出受检异常没有返回值,而 call 方法则可以抛出受检异常并可设置返回值。两者的方 法体都是线程执行体。

### fork&join 模型

该模型包含**递归思想和回溯思想**,递归用来拆分任务,回溯用合并结果。 可以用来处理一些可以进行拆分的大任务。其主要是把一个**大任务逐级拆分为多个子任务**,然后分别在子线程中 执行,当每个子线程执行结束之后逐级回溯,返回结果进行汇总合并,最终得出想要的结果。
这里模拟一个摘苹果的场景:有 100 棵苹果树,每棵苹果树有 10 个苹果,现在要把他们摘下来。为了节约时间,规定每个线程最多只能摘 10 棵苹树以便于节约时间。各个线程摘完之后 汇总计算总苹果树。

### actor 模型

actor 模型属于一种基于**消息传递机制并行任务处理思想**,它以**消息**的形式来进行线程间数据传输,避免了全局变量的使用,进而避免了数据同步错误的隐患。actor 在接受到消息之后可 以自己进行处理,也可以继续传递(分发)给其它 actor 进行处理。在使用 actor 模型的时候需 要使用第三方 Akka 提供的框架。

### 生产者消费者模型

生产者消费者模型都比较熟悉,其核心是使用**一个缓存来保存**任务。开启一个/多个线程来生产任务,然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开,生产者不需要处理任务,只负责向生成任务然后保存到缓存。而消费者只需要从缓存 中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。 比如,生成的任务速度较快,那么就可以灵活的多开启几个消费者线程进行处理,这样就可以避 免任务的处理响应缓慢的问题。

### master-worker 模型

master-worker 模型类似于任务分发策略,开启一个 master 线程接收任务,然后在 master中根据任务的具体情况进行分发给其它 worker 子线程,然后由子线程处理任务。如需返回结果, 则 worker 处理结束之后把处理结果返回给 master。

## 协程

### 定义

协程,又称微线程,纤程,英文名 Coroutine。协程看上去也是子程序,但执行过程中,在子程序内部可中断,然后转而执行别的子程序,在适当的时候再返回来接着执行。

```Python
def A(): 
    print '1' 
    print '2'
    print '3'
def B() : 
    print 'x' 
    print 'y' 
    print 'z'
```

输出可能是12x3yz A执行过程中 随时可能中断 去执行B,B也可能在执行过程中 中断去执行A 但协程是在一个线程内运行。

### 协程优势

* 协程执行效率极高 

* 协程由程序自身控制 没有线程切换的开销 所以线程数目越多 协程优势越明显

* 协程不需要锁机制 不村子啊写变量冲突 只需要判断状态
* 在协程上利用多核 CPU 呢——多进程+协程,既充分利用多核,又充分发挥协程的高效率,可获得极高的性能。

>Python 对协程的支持还非常有限,用在 generator 中的 yield 可以一定程度上实现协程。虽然支持不完全,但已经可以发挥相当大的威力了

## 多线程

### 单核机器线程加锁原因

* 实现进程同步和通信

* 防止共享数据修改引起冲突

### 线程需要保存的上下文

* 线程ID
* 线程状态
* 堆栈
* 寄存器状态

### 寄存器作用

* SP:堆栈指针,指向当前栈的栈顶地址
* PC:程序计数器,存储下一条将要执行的指令 
* EAX:累加寄存器,用于加法乘法的缺省寄存器

### 线程同步的方式

* 信号量 信号量是一种特殊的变量,可用于线程同步。它只取自然数值,并且只支持两种操作: 
  * P(SV):如果信号量 SV 大于 0,将它减一;如果 SV 值为 0,则挂起该线程。 
  * V(SV):如果有其他进程因为等待 SV 而挂起,则唤醒,然后将 SV+1;否则直接将 SV+1。 
  * 其系统调用为:
    *  sem_wait(sem_t *sem):以原子操作的方式将信号量减 1,如果信号量值为 0,则 sem_wait将被阻塞,直到这个信号量具有非 0 值。 
    * sem_post(sem_t *sem):以原子操作将信号量值+1。当信号量大于 0 时,其他正在调用sem_wait 等待信号量的线程将被唤醒。
* 互斥量 
  * 互斥量又称互斥锁,主要用于线程互斥,不能保证按序访问,可以和条件锁一起实现同步。
    当进入临界区 时,需要获得互斥锁并且加锁;当离开临界区时,需要对互斥锁解锁,
    以唤醒其他等待该互斥锁的线程。其主要的系统调用如下: 
    * pthread_mutex_init:初始化互斥锁 
    * pthread_mutex_destroy:销毁互斥锁 
    * pthread_mutex_lock:以原子操作的方式给一个互斥锁加锁,如果目标互斥锁已经被上锁,pthread_mutex_lock 调用将阻塞,直到该互斥锁的占有者将其解锁。 
    * pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。

* 条件变量 

  * 条件变量,又称条件锁,用于在线程之间同步共享数据的值。条件变量提供一种线程间通
    信机制:当某个共享数据达到某个值时,唤醒等待这个共享数据的一个/多个线程。即,当某个 共享变量等于某个值时,调用 signal/broadcast。此时操作共享变量时需要加锁。其主要的系 统调用如下:
  * pthread_cond_init:初始化条件变量 
  * pthread_cond_destroy:销毁条件变量 
  * pthread_cond_signal:唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。 

  pthread_cond_wait:等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入 wait 状态前首先进行解锁,然后接收到信号后会再加锁,保证该线程对共享资源正 确访问。

## fork 和 vfork

### fork:

创建一个和当前进程映像一样的进程可以通过 fork( )系统调用:

```C++
#include <sys/types.h> 
#include <unistd.h> 
pid_t fork(void);
```

* 成功调用 fork( )会创建一个新的进程,它几乎与调用 fork( )的进程一模一样,这两个进
  程都会继续运行。在子进程中,成功的 fork( )调用会返回 0。在父进程中 fork( )返回子进程 的 pid。如果出现错误,fork( )返回一个负值。

* 最常见的 fork( )用法是创建一个新的进程,然后使用 exec( )载入二进制映像,替换当前
  进程的映像。这种情况下,派生(fork)了新的进程,而这个子进程会执行一个新的二进制可执 行文件的映像。这种"派生加执行"的方式是很常见的。

  > 在早期的 Unix 系统中,创建进程比较原始。当调用 fork 时,内核会把所有的内部数据结构复制一份,复制进程的页表项,然后把父进程的地址空间中的内容逐页的复制到子进程的地址空 间中。但从内核角度来说,逐页的复制方式是十分耗时的。现代的 Unix 系统采取了更多的优化, 例如 Linux,采用了写时复制的方法,而不是对父进程空间进程整体复制。

### vfork

```c++
#include <sys/types.h> 
#include <unistd.h> 
pid_t vfork(void);
```

* 除了子进程必须要立刻执行一次对 exec 的系统调用,或者调用_exit( )退出,对 vfork( )
  的成功调用所产生的结果和 fork( )是一样的。
* vfork( )会挂起父进程直到子进程终止或者运行 了一个新的可执行文件的映像。通过这样的方式,vfork( )避免了地址空间的按页复制。在这个 过程中,父进程和子进程共享相同的地址空间和页表项。实际上 vfork( )只完成了一件事:复 制内部的内核数据结构。因此,子进程也就不能修改地址空间中的任何内存。
* vfork( )是一个历史遗留产物,Linux 本不应该实现它。需要注意的是,即使增加了写时复
  制,vfork( )也要比 fork( )快,因为它没有进行页表项的复制。然而,写时复制的出现减少了 对于替换 fork( )争论。实际上,直到 2.2.0 内核,vfork( )只是一个封装过的 fork( )。因为 对 vfork( )的需求要小于 fork( ),所以 vfork( )的这种实现方式是可行的。

### 写时复制

Linux 采用了写时复制的方法,以减少 fork 时对父进程空间进程整体复制带来的开销。

写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单:如果有多
个进程要读取它们自己的那部门资源的副本,那么复制是不必要的。每个进程只要保存一个指向 这个资源的指针就可以了。只要没有进程要去修改自己的"副本",就存在着这样的幻觉:每个 进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源"副本",那么就会复制那份资源,并把复制的那份提供给进程。不过其中的复制对进程来说是透明 的。这个进程就可以修改复制后的资源了,同时其他的进程仍然共享那份没有修改过的资源。所 以这就是名称的由来:在写入时进行复制。
写时复制的主要好处在于:如果进程从来就不需要修改资源,则不需要进行复制。惰性算法
的好处就在于它们尽量推迟代价高昂的操作,直到必要的时刻才会去执行。 在使用虚拟内存的情况下,写时复制(Copy-On-Write)是以页为基础进行的。所以,只要进程不修改它全部的地址空间,那么就不必复制整个地址空间。在 fork( )调用结束后,父进程 和子进程都相信它们有一个自己的地址空间,但实际上它们共享父进程的原始页,接下来这些页 又可以被其他的父进程或子进程共享。
写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。
如果有进程试图修改一个页,就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行 一次透明复制。这时会清除页面的 COW 属性,表示着它不再被共享。
现代的计算机系统结构中都在内存管理单元(MMU)提供了硬件级别的写时复制支持,所以
实现是很容易的。 在调用 fork( )时,写时复制是有很大优势的。因为大量的 fork 之后都会跟着执行 exec,那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间:如果子进程立执行一个新的二进制可执行文件的映像,它先前的地址空间就会被交换出去。写时复制可以对这 种情况进行优化

### fork 和 vfork 的区别: 

* fork( )的子进程拷贝父进程的数据段和代码段;vfork( )的子进程与父进程共享数据段 
* fork( )的父子进程的执行次序不确定;vfork( )保证子进程先运行,在调用 exec 或 exit
  之前与父进程数据是共享的,在它调用 exec 或 exit 之后父进程才可能被调度运行。 
* vfork( )保证子进程先运行,在它调用 exec 或 exit 之后父进程才可能被调度运行。如
  果在调用这两个函数之前子进程依赖于父进程的进一步动作,则会导致死锁。
* 当需要改变共享数据段中变量的值,则拷贝父进程。

### 例程

```C++
int main(void) 
{
	pid_t pid; 
    signal(SIGCHLD, SIG_IGN); 
    printf("before fork pid:%d\n", getpid()); 
    int abc = 10; 
    pid = fork(); 
    if (pid == -1) 
    {
		//错误返回
		perror("tile"); return -1;
	} 
    if (pid > 0) 
    {
        abc++; //父进程空间 
        printf("parent:pid:%d \n", getpid()); 
        printf("abc:%d \n", abc); sleep(20);
	} 
    else if (pid == 0) 
    {
		//子进程空间
        abc++; 
        printf("child:%d,parent: %d\n", getpid(), getppid()); 
        printf("abc:%d", abc);
	} 
    printf("fork after...\n");
}
```



## 修改最大句柄数

* 默认为1024 个 在Linux 服务器并发量较大的情况下 系统会报too many open files的错误
* 方法一:ulimit -n <可以同时打开的文件数>将当前进程的最大句柄数修改为指定的参数(注:该方法只针对当前进程有效,重新打开一个 shell 或者重新开启一个进程,参数还是之前的值)
  * 首先用 ulimit - a 查询Linux相关的参数 其中open files时最大句柄数 默认为1024个
  * 修改 ulimit -n 2048 将最大句柄数修改为 2048 个
* 方法二:修改Linux参数

vi /etc/security/limits.conf 添加 

```shell
* soft noflie 65536
* hard nofile 65536
```


将最大句柄数改为 65536 修改以后保存,注销当前用户,重新登录,修改后的参数就生效了

## 并发和并行

* 并发(concurrency):**指宏观上看起来两个程序在同时运行**,比如说在单核 cpu 上的多任
  务。但是从微观上看两个程序的指令是交织着运行的,你的指令之间穿插着我的指令,我的指令 之间穿插着你的,在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能,只能提 高效率。
* 并行(parallelism):**指严格物理意义上的同时运行**,比如多核 cpu,两个程序分别运行
  在两个核上,两者之间互不影响,单个周期内每个程序都运行了自己的指令,也就是运行了两条 指令。这样说来并行的确提高了计算机的效率。所以现在的 cpu 都是往多核方面发展

## 锁

### Linux 四种锁的机制

#### 互斥锁:

mutex,用于保证在任何时刻,都只能有一个线程访问该对象。当获取锁操作失败时,线程会进入睡眠,等待锁释放时被唤醒。

#### 读写锁:

rwlock,分为读锁和写锁。处于读操作时,可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态,直到写 锁释放时被唤醒。 

> 注意:写锁会阻塞其它读写锁。当有一个线程获得写锁在写时,读锁也不能 被其它线程获取;写者优先于读者(一旦有写者,则后续读者必须等待,唤醒时优先考虑写者)。 适用于读取数据的频率远远大于写数据的频率的场合。

#### 自旋锁:

spinlock,在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时,不会进入睡眠,而是会在原地自旋,直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的 消耗,在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长,则会非常浪费 CPU 资源。

#### RCU

即 read-copy-update,在修改数据时,首先需要读取数据,然后生成一个副本,对副本进行修改。修改完成后,再将老数据 update 成新的数据。使用 RCU 时,读者几乎不需要同步 开销,既不需要获得锁,也不使用原子指令,不会导致锁竞争,因此就不用考虑死锁问题了。而 对于写者的同步开销较大,它需要复制被修改的数据,还必须使用锁机制同步并行其它写者的修 改操作。在有大量读操作,少量写操作的情况下效率非常高。

###  多线程同步锁的机制

* 同步的时候用一个互斥量,在访问共享资源前对互斥量进行加锁,在访问完成后释放互斥量上的锁。
* 对互斥量进行加锁以后,任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线 程释放该互斥锁。
* 如果释放互斥锁时有多个线程阻塞,所有在该互斥锁上的阻塞线程都会变成可 运行状态,第一个变为运行状态的线程可以对互斥量加锁,其他线程将会看到互斥锁依然被锁住, 只能回去再次等待它重新变为可用。
* 在这种方式下,每次只有一个线程可以向前执行。

### 两个进程访问临界区资源 会不会出现都获得自旋锁的情况。

单核CPU且开了抢占可以造成情况。

### 死锁

死锁是指两个或两个以上进程在执行过程中,因争夺资源而造成的下相互等待的现象。

死锁发生的四个必要条件如下: 

* 互斥条件:进程对所分配到的资源不允许其他进程访问,若其他进程访问该资源,只能等待,
  直至占有该资源的进程使用完成后释放该资源; 

* 请求和保持条件:进程获得一定的资源后,又对其他资源发出请求,但是该资源可能被其他
  进程占有,此时请求阻塞,但该进程不会释放自己已经占有的资源 

* 不可剥夺条件:进程已获得的资源,在未完成使用之前,不可被剥夺,只能在使用后自己释放

* 环路等待条件:进程发生死锁后,必然存在一个进程-资源之间的环形链 

解决死锁的方法即破坏上述四个条件之一,主要方法如下: 

* 资源一次性分配,从而剥夺请求和保持条件 
* 可剥夺资源:即当进程新的资源未得到满足时,释放已占有的资源,从而破坏不可剥夺的条件
* 资源有序分配法:系统给每类资源赋予一个序号,每个进程按编号递增的请求资源,释放则 相反,从而破坏环路等待的条件

### windows消息机制

当用户有操作(鼠标,键盘等)时,系统会将这些时间转化为消息。每个打开的进程系统都为其维护了一个消息队列,系统会将这些消息放到进程的消息队列中,而应用程序会循环从消息队 列中取出来消息,完成对应的操作。

### C++锁

* 互斥锁、条件变量、自旋锁、读写锁

### 单核机器线程加锁原因

- 实现进程同步和通信
- 防止共享数据修改引起冲突

## 进程状态图

![C++面试_7_7.jpg](/images\C++面试_7_7.jpg)

* 创建状态:进程正在被创建 

* 就绪状态:进程被加入到就绪队列中等待 CPU 调度运行 

* 执行状态:进程正在被运行 

* 等待阻塞状态:进程因为某种原因,比如等待 I/O,等待设备,而暂时不能运行。 

* 终止状态:进程运行完毕

### 交换技术

当多个进程竞争内存资源时,会造成内存资源紧张,并且,如果此时没有就绪进程,处理机 会空闲,I/0 速度比处理机速度慢得多,可能出现全部进程阻塞等待 I/O。针对以上问题,提出了两种解决方法:

	* 交换技术:换出一部分进程到外存,腾出内存空间
	* 虚拟存储技术:每个进程只能装入一部分程序和数据。

   在交换技术上,将内存暂时不能运行的进程,或者暂时不用的数据和程序,换出到外存,来 腾出足够的内存空间,把已经具备运行条件的进程,或进程所需的数据和程序换入到内存。
从而出现了进程的挂起状态:进程被交换到外存,进程状态就成为了挂起状态。

### 阻塞

活动阻塞,静止阻塞,活动就绪,静止就绪 

* 活动阻塞:进程在内存,但是由于某种原因被阻塞了。

* 静止阻塞:进程在外存,同时被某种原因阻塞了。

* 活动就绪:进程在内存,处于就绪状态,只要给 CPU 和调度就可以直接运行。

* 静止就绪:进程在外存,处于就绪状态,只要调度到内存,给 CPU 和调度就可以运行。

  从而出现了: 

  活动就绪 —— 静止就绪 (内存不够,调到外存) 

  活动阻塞 —— 静止阻塞 (内存不够,调到外存) 

  执行 —— 静止就绪 (时间片用完)

## 系统调用

系统调用 又叫系统呼叫 运行在使用者空间的程序向操作系统使用者向操作系统内核请求要求**更高的权限运行**服务。系统调用提供了**用户程序和操作系统之间的接口**

操作系统中的状态分为**管态**[核心态]和**目态**[用户态]

大多数系统交互式操作要求在内核态运行。(设备IO操作 和进程间通信)

**特权指令**: 一类只能在核心态下运行而不能在用户态下运行的特殊指令

>应用程序有时会需要一些危险的、权限很高的指令,如果把这些权限放心地交给用户程序是
>很危险的(比如一个进程可能修改另一个进程的内存区,导致其不能运行),但是又不能完全不给 这些权限。于是有了系统调用,危险的指令被包装成系统调用,用户程序只能调用而无权自己运 行那些危险的指令。另外,计算机硬件的资源是有限的,为了更好的管理这些资源,所有的资源 都由操作系统控制,进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口,这个 入口就是系统调用。

```C++
//对文件进行写操作,程序向打开的文件写入字符串"hello world",open 和 write 都是系统调用。如下:
#include<stdio.h>
#include<stdlib.h> 
#include<string.h> 
#include<errno.h> 
#include<unistd.h> 
#include<sys/types.h> 
#include<sys/stat.h>
#include<fcntl.h> 
int main(int argc, char *argv[]) 
{
	if (argc<2) return 0;
	//用读写追加方式打开一个已经存在的文件 
    int fd = open(argv[1], O_RDWR | O_APPEND); 
    if (fd == -1) 
    {
		printf("error is %s\n", strerror(errno));
	} 
    else 
    {
		//打印文件描述符号 
    	printf("success fd = %d\n", fd); 
        char buf[100]; 
        memset(buf, 0, sizeof(buf)); 
        strcpy(buf, "hello world\n"); 
        write(fd, buf, strlen(buf)); 
        close(fd);
	} 
    return 0;
} 
//还有写数据 write,创建进程 fork,vfork 等都是系统调用
```

### 用户态转到内核态

#### 切换的三种方式

* 系统调用

  这是用户进程主动要求切换到内核态的一种方式,用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中 断来实现,例如 Linux 的 ine 80h 中断。

* 异常

  当 CPU 在执行运行在用户态的程序时,发现了某些事件不可知的异常,这是会触发由当前运行进程切换到处理此。异常的内核相关程序中,也就到了内核态,比如缺页异常。

* 外围设备中断

  当外围设备完成用户请求的操作之后,会向 CPU 发出相应的中断信号,这时 CPU 会暂停执行下一条将要执行的指令,转而去执行中断信号的处理程序,如果先执行的指令是用户态下的程 序,那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成,系 统会切换到硬盘读写的中断处理程序中执行后续操作等。

#### 切换操作

1. 从当前进程的描述符中提取其内核栈的 ss0 及 esp0 信息。

2. 使用 ss0 和 esp0 指向的内核栈将当前进程的 cs,eip,eflags,ss,esp 信息保存起来,这个过程也完成了由用户栈找到内核栈的切换过程,同时保存了被暂停执行的程序的下一条指令。

3. 将先前由中断向量检索得到的中断处理程序的 cs,eip 信息装入相应的寄存器,开始执行中断处理程序,这时就转到了内核态的程序执行了。

## 服务器设计

### 如何设计server 使得能够接受多个客户端的请求

多线程、线程池、io复用

### 死循环+来连接时新建线程的方法效率有点低,怎么改进?

提前创建好一个线程池,用生产者消费者模型,创建一个任务队列,队列作为临界资源,有了新连接,就挂在到任务队列上,队列为空所有线程睡眠。改进死循环:使用 select epoll 这 样的技术

### 请问怎么唤醒被阻塞的 socket 线程?

参考回答: 给阻塞时候缺少的资源

### 请问怎样确定当前线程是繁忙还是阻塞?

使用ps命令

### 就绪的线程在等待什么

被调度使用CPU的运行权限

###  server 端监听端口 但客户端没有链接进来，此时进程处于什么状态？

这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如果使 用了 epoll,select 等这样的 io 复用情况下，处于运行状态

### 请问怎么实现线程池

* 设置一个生产者消费者队列，作为临界资源 
* 初始化 n 个线程，并让其运行起来，加锁去队列取任务运行 
* 当任务队列为空的时候，所有线程阻塞 
* 当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通 知阻塞中的一个线程

## 微内核和宏内核

### 宏内核

除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等都集成在内核里面，例如 linux 内核。 

优点：效率高。 

缺点：稳定性差，开发过程中的 bug 经常会导致整个系统挂掉。

### 微内核 

内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程去实现的。 

优点：稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃 

缺点：效率低。

典型代表 QNX，QNX 的文件系统是跑在用户态的进程，称为 resmgr 的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了

## 僵尸进程

* 正常进程

  正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运 行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工 作终止之后，它的父进程需要调用 wait()或者 waitpid()系统调用取得子进程的终止状态。

  unix 提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每 个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然 为其保留一定的信息，直到父进程通过 wait / waitpid 来取时才释放。保存信息包括：

  * 进程号 the process ID 

  * 退出状态 the termination status of the process 

  *  运行时间 the amount of CPU time taken by the process 等

* 孤儿进程

  一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进 程将被 init 进程(进程号为 1)所收养，并由 init 进程对它们完成状态收集工作。

* 僵尸进程

  * 一个进程使用 fork 创建子进程，如果**子进程退出，而父进程并没有调用 wait 或 waitpid 获取子 进程的状态信息**，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。 

  * 僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。
    如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。 如果父进程能及时 处理，可能用 ps 命令就来不及看到子进程的僵尸状态，但这并不等于子进程 不经过僵尸状态。
    如果父进程在子进程结束之前退出，则子进程将由 init 接管。init 将会以父进程的身份对僵尸 状态的子进程进行处理。
  * 危害：
    如果进程不调用 wait / waitpid 的话， 那么保留的那段信息就不会释放，其进程号就会一直被 占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程 号而导致系统不能产生新的进程。
  * 外部消灭：
    通过 kill 发送 SIGTERM 或者 SIGKILL 信号消灭产生僵尸进程的进程，它产生的僵死进程就变成 了孤儿进程，这些孤儿进程会被 init 进程接管，init 进程会 wait()这些孤儿进程，释放它们占 用的系统进程表中的资源
  * 内部解决：
    1、子进程退出时向父进程发送 SIGCHILD 信号，父进程处理 SIGCHILD 信号。在信号处理函数中 调用 wait 进行处理僵尸进程。
    2、fork 两次，原理是将子进程成为孤儿进程，从而其的父进程变为 init 进程，通过 init 进程 可以处理僵尸进程。

## reactor 模型组成

* reactor 模型要求主线程只负责监听文件描述上是否有事件发生,有的话就立即将该事件通
  知工作线程,除此之外,主线程不做任何其他实质性的工作,读写数据.接受新的连接以及处理 客户请求均在工作线程中完成。其模型组成如下:.

![image-20200705161340852](E:/Notes/MarkDown/计算机课程学习/imgs/C++面试_5_1.jpg)

* Handle:即操作系统中的句柄,是对资源在操作系统层面上的一种抽象,它可以是打开
  的文件.一个连接(Socket).Timer 等。由于 Reactor 模式一般使用在网络编程中,因而这里一 般指 Socket Handle,即一个网络连接。
* Synchronous Event Demultiplexer(同步事件复用器):阻塞等待一系列的 Handle 中
  的事件到来,如果阻塞等待返回,即表示在返回的 Handle 中可以不阻塞的执行返回的事件类型。 这个模块一般使用操作系统的 select 来实现。
* Initiation Dispatcher:用于管理 Event Handler,即 EventHandler 的容器,用以注
  册.移除 EventHandler 等;另外,它还作为 Reactor 模式的入口调用 Synchronous Event Demultiplexer 的 select 方法以阻塞等待事件返回,当阻塞等待返回时,根据事件发生的 Handle 将其分发给对应的 Event Handler 处理,即回调 EventHandler 中的 handle_event()方法。
* Event Handler:定义事件处理方法:handle_event(),以供 InitiationDispatcher 回
  调使用。 
* Concrete Event Handler:事件 EventHandler 接口,实现特定事件处理逻辑。

## Reactor 模型 与 Proactor 模型 区别



Reactor被动的等待指示事件的到来并作出反应，有一个等待的过程，做什么都要先放入到监听事件集合中等待handler可用时再进行操作，实现相对简单，对于耗时短的处理场景比较高效，但Reactor处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理。

Proactor直接调用异步读写操作，调用完后立刻返回，实现了一个主动的事件分离和分发模型；这种设计允许多个任务并发的执行，从而提高吞吐量；并可执行耗时长的任务（各个任务间互不影响），Proactor性能更高，能够处理耗时长的并发场景，但Proactor实现逻辑复杂；依赖操作系统对异步的支持，目前实现了纯异步操作的操作系统少，实现优秀的如windows IOCP，但由于其windows系统用于服务器的局限性，目前应用范围较小；而Unix/Linux系统对纯异步的支持有限，应用事件驱动的主流还是通过select/epoll来实现。

## 自己设置下单线程方式处理高并发

在单线程模型中,可以采用 I/O 复用来提高单线程处理多个请求的能力,然后再采用事件驱 动模型,基于异步回调来处理事件来

## select epoll 区别 原理 性能 限制

  ![C++面试_5_2.jpg](/images\C++面试_5_2.jpg)

  * IO多路复用

    * IO 复用模型在阻塞 IO 模型上多了一个 select 函数,select 函数有一个参数是文件描述符集合,意思就是对这些的文件描述符进行循环监听,当某个文件描述符就绪的时候,就对这个文 件描述符进行处理。
      这种 IO 模型是属于阻塞的 IO。但是由于它可以对多个文件描述符进行阻塞监听,所以它的 效率比阻塞 IO 模型高效。【有点像中断向量的意思】
    * IO 多路复用就是我们说的 select,poll,epoll。select/epoll 的好处就在于单个 process就可以同时处理多个网络连接的 IO。
      * 基本原理 
        1. select,poll,epoll 这个 function 会 不断的轮询所负责的所有 socket,当某个 socket 有数据到达了,就通知用户进程。
        2. 当用户进程调用了 select,那么整个进程会被 block,而同时,kernel 会"监视"所有 select负责的 socket,
        3. 当任何一个 socket 中的数据准备好了,select 就会返回。
        4. 这个时候用户进程再 调用 read 操作,将数据从 kernel 拷贝到用户进程。
      * 所以,I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符,而这些文件描述符(套接字描述符)其中的任意一个进入读就绪状态,select()函数就可以返回。
      * I/O 多路复用和阻塞 I/O 其实并没有太大的不同,事实上,还更差一些。因为这里需要使用两个system call (select 和 recvfrom),而blocking IO只调用了一个system call (recvfrom)。但是,用 select 的优势在于它可以同时处理多个 connection。
        所以,如果处理的连接数不是很高的话,使用 select/epoll 的 web server 不一定比使用multi-threading + blocking IO 的 web server 性能更好,可能延迟还更大。select/epoll 的优势并不是对于单个连接能处理得更快,而是**在于能处理更多的连接**。)
      * 在 IO multiplexing Model 中,实际中,对于每一个 socket,一般都设置成为 non-blocking,但是,如上图所示,整个用户的 process 其实是一直被 block 的。只不过 process 是被 select这个函数 block,而不是被 socket IO 给 block。

  * select
    select:是最初解决 IO 阻塞问题的方法。用结构体 fd_set 来告诉内核监听多个文件描述符,该结构体被称为描述符集。由数组来维持哪些描述符被置位了。对结构体的操作封装在三个宏定义中。通过轮寻来查找是否有描述符要被处理。

    * 存在的问题:

      * 内置数组的形式使得 select 的最大文件数受限与 FD_SIZE;

      * 每次调用 select 前都要重新初始化描述符集,将 fd 从用户态拷贝到内核态,每次调用select 后,都需要将 fd 从内核态拷贝到用户态;

      * 轮寻排查当文件描述符个数很多时,效率很低;

  * poll

    * 通过一个可变长度的数组解决了 select 文件描述符受限的问题。
    * 数组中元素是结构
      体,该结构体保存描述符的信息,每增加一个文件描述符就向数组中加入一个结构体,结构体只需要拷贝一次到内核态。
    * poll 解决了 select 重复初始化的问题。轮寻排查的问题未解决。

  * epoll

    * 轮寻排查所有文件描述符的效率不高,使服务器并发能力受限。因此,epoll 采用
      只返回状态发生变化的文件描述符,便解决了轮寻的瓶颈。

    * epoll 对文件描述符的操作有两种模式:LT(level trigger)和 ET(edge trigger)。LT模式是默认模式

    * LT 模式
      LT(level triggered)是缺省的工作方式,并且同时支持 block 和 no-block socket.在这种做法中,内核告诉你一个文件描述符是否就绪了,然后你可以对这个就绪的 fd 进行 IO 操作。如果你不作任何操作,内核还是会继续通知你的。

    * ET 模式 

      ET(edge-triggered)是高速工作方式,只支持 no-block socket。在这种模式下,当描述符从未就绪变为就绪时,内核通过 epoll 告诉你。然后它会假设你知道文件描述符已经就绪,并且 不会再为那个文件描述符发送更多的就绪通知,直到你做了某些操作导致那个文件描述符不再为 就绪状态了(比如,你在发送,接收或者接收请求,或者发送接收的数据少于一定量时导致了一 个 EWOULDBLOCK 错误)。但是请注意,如果一直不对这个 fd 作 IO 操作(从而导致它再次变成未 就绪),内核不会发送更多的通知(only once)
      ET 模式在很大程度上减少了 epoll 事件被重复触发的次数,因此效率要比 LT 模式高。epoll工作在 ET 模式的时候,必须使用非阻塞套接口,以避免由于一个文件句柄的阻塞读/阻塞写操作 把处理多个文件描述符的任务饿死。

    * LT 模式与 ET 模式的区别如下: 

      * LT 模式:当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序,应用程序可以不立即处理该事件。下次调用 epoll_wait 时,会再次响应应用程序并通知此事件。 *
      * ET 模式:当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序,应用程序必须立即处理该事件。如果不处理,下次调用 epoll_wait 时,不会再次响应应用程序并通知此事件。
    
*  epoll 是一个可扩展的 Linux I/O 事件通知机制。

      * [epoll详解](https://zhuanlan.zhihu.com/p/63179839)

      int epoll_create(int size); i

      nt epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
      int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout); 

      首先创建一个 epoll 对象,然后使用 epoll_ctl 对这个对象进行操作,把需要监控的描述添加进去,这些描述如将会以epoll_event结构体的形式组成一颗红黑树,接着阻塞在epoll_wait, 进入循环,当某个 fd 上有事件发生时,内核将会把其对应的结构体放入到一个链表中,返回 有事件发生的链表。

    > n 个整数的无序数组,找到每个元素后面比它大的第一个数,要求时间复杂度为 O(N) -> **用栈**

## 异步编程的事件循环

* 事件循环就是不停循环等待事件的发生，然后将这个事件的所有处理器，以及他们订阅这个事件 的时间顺序依次依次执行。
* 当这个事件的所有处理器都被执行完毕之后，事件循环就会开始继续 等待下一个事件的触发，不断往复。当同时并发地处理多个请求时，以上的概念也是正确的，
* 可 以这样理解：在单个的线程中，事件处理器是一个一个按顺序执行的。即如果某个事件绑定了两 个处理器，那么第二个处理器会在第一个处理器执行完毕后，才开始执行。在这个事件的所有处 理器都执行完毕之前，事件循环不会去检查是否有新的事件触发。
* 在单个线程中，一切都是有顺 序地一个一个地执行的！！